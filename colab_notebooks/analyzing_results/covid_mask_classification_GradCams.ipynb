{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_mask_classification_activations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fuh-B6pQdzAg"
      },
      "source": [
        "### Mounting Drive Unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V50ub1mHHXA",
        "outputId": "9f96032c-145f-4b56-fb1e-0a65b994c103"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsqg4syId2IU"
      },
      "source": [
        "### Clonning the repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC5PoINad9nt",
        "outputId": "22f170b2-5413-4551-ffe9-7e8490d72305"
      },
      "source": [
        "!git clone https://FabricioCrespo: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@github.com/FabricioCrespo/covid_mask_classificator.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'covid_mask_classificator'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Total 37 (delta 0), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaTYnURfoTR3",
        "outputId": "0b6ea1b0-b8e4-4322-b6fe-70c5c3923fd6"
      },
      "source": [
        "%cd covid_mask_classificator/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/covid_mask_classificator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyVz5vAVEYSZ"
      },
      "source": [
        "## Installing the tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqESyd6-ES51",
        "outputId": "bff10257-2b2d-4a48-abc4-a493e1b9908e"
      },
      "source": [
        "!pip install grad-cam"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.3.7.tar.gz (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 5.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (0.11.1+cu111)\n",
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.1.2.30)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from grad-cam) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.1->grad-cam) (3.10.0.2)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.3.7-py3-none-any.whl size=25953 sha256=6a4920bf7084057d34effa433149c6cefc8c52d7ce125020fe7aa0e05ca17df4\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/ab/9c/53c523785edffdc6c61755cf82e0dac3342d0d36190c187894\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.3.7 ttach-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq8NN-93MrSd"
      },
      "source": [
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
        "                                         deprocess_image, \\\n",
        "                                         preprocess_image\n",
        "from torchvision.models import resnet50\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Naq2Y8TPMunI"
      },
      "source": [
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "# 1. Load model \n",
        "custom_model_path='/content/drive/MyDrive/TESIS/after_TicEc/Classification/modelos_diciembre_2021/resnet-18-Cross_ADAGRAD_15epochs_dataset4_3clases_gender_transforms.pt'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = torch.load(custom_model_path)\n",
        "\n",
        "# 1. Load model \n",
        "#model = resnet50(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYmjz6THM6uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fffe193-9dd5-48a9-e921-7aea66317142"
      },
      "source": [
        "target_layers = [model.layer1[-1]]\n",
        "print(target_layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BasicBlock(\n",
            "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8PyZrOM9rR"
      },
      "source": [
        "image_path = '/content/non_compliant.png'\n",
        "rgb_img = cv2.imread(image_path, 1)[:, :, ::-1]   # 1 Is read rgb\n",
        "rgb_img = np.float32(rgb_img) / 255\n",
        "\n",
        "# preprocess_image effect ： Normalized image , And to tensor\n",
        "input_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406],\n",
        "                                             std=[0.229, 0.224, 0.225])   # torch.Size([1, 3, 224, 224])\n",
        "# Create an input tensor image for your model..\n",
        "# Note: input_tensor can be a batch tensor with several images!\n",
        "input_tensor=input_tensor.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAh-hbIDNGGM"
      },
      "source": [
        "# Construct the CAM object once, and then re-use it on many images:\n",
        "# 4. initialization GradCAM, Including models , Target layer and whether to use cuda\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp8DlpAWOcEg"
      },
      "source": [
        "# If target_category is None, the highest scoring category\n",
        "# will be used for every image in the batch.\n",
        "# target_category can also be an integer, or a list of different integers\n",
        "# for every image in the batch.\n",
        "# 5. Select the target category , If not set , The default is the one with the highest score \n",
        "target_category = None # 281"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_6i-DJFOmZo"
      },
      "source": [
        "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "# 6.  Calculation cam\n",
        "grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)  # [batch, 224,224]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSZOP9-UPKzT",
        "outputId": "8967d9be-b53c-4f4b-8af2-f9c33be4df8f"
      },
      "source": [
        "# In this example grayscale_cam has only one image in the batch:\n",
        "# 7. Display and save the heat map , grayscale_cam It's a batch Result , Only one can be selected for display \n",
        "grayscale_cam = grayscale_cam[0]\n",
        "visualization = show_cam_on_image(rgb_img, grayscale_cam)  # (224, 224, 3)\n",
        "cv2.imwrite(f'non_compliant_activation.jpg', visualization)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_G4O4SkVHS8",
        "outputId": "091c14b2-5b90-428e-c2ce-b7b0c2441d3b"
      },
      "source": [
        "!python cam.py -ln 4 -sn 1 --image-path '/content/covid_mask_classificator/images/non_compliant/4.png' --method 'gradcam'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU for computation\n",
            "[BasicBlock(\n",
            "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPbOxat_Q9Zg"
      },
      "source": [
        "References:\n",
        "\n",
        "https://cdmana.com/2021/05/20210511222601751h.html\n",
        "\n",
        "https://github.com/jacobgil/pytorch-grad-cam\n",
        "\n",
        "https://towardsdatascience.com/class-activation-mapping-using-transfer-learning-of-resnet50-e8ca7cfd657e\n",
        "\n",
        "http://cnnlocalization.csail.mit.edu/\n",
        "\n",
        "https://arxiv.org/pdf/1512.04150.pdf"
      ]
    }
  ]
}